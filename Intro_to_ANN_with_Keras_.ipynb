{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/phaneo/Hands-on-ML/blob/main/Intro_to_ANN_with_Keras_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "[![Open In Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/phaneo/Hands-on-ML/blob/main/Intro_to_ANN_with_Keras_.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__Y8bw2FueCY"
   },
   "source": [
    "# **Perceptrons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dCYv7pKktO5L"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X= iris.data[:, (2, 3)]\n",
    "y = (iris.target ==0).astype(int)\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)\n",
    "y_pred = per_clf.predict([[2, 0.5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "W33XGkvguNHZ",
    "outputId": "f12c2cd7-be93-414f-fae5-cc5d75926322"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "MhzPnw_OIJA1",
    "outputId": "d634f0c6-dc05-4e24-8e6f-4f22fd27d798"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Rlkx3e-2ILoG"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pGfs6F_WI19P"
   },
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000] , y_train_full[5000:]\n",
    "X_test = X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "rVvZV9OVESBY",
    "outputId": "d65e753d-0ab6-44ec-d9d5-8490b38edc42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0], cmap='binary')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jylVcfonEbXQ",
    "outputId": "d285a3ba-47c2-4a52-a900-277514dc1cb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YPDLc7r3J57k"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-01 04:54:24.256101: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2YFk14qsDcQ"
   },
   "source": [
    "We can also pass a list of layers when creating a Sequential model:\n",
    "\n",
    "```\n",
    "model = keras.models.Sequential([\n",
    "                                 keras.layers.Flatten(input_shape=[28,28]),\n",
    "                                 keras.layers.Dense(300, activation=\"relu\"),\n",
    "                                 keras.layers.Dense(100, activation=\"relu\"),\n",
    "                                 keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UjXkcfnnsdRZ",
    "outputId": "f29d8b42-94b9-4657-a4cd-90c5f59e5159"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "id": "oeLRDuOnsy-4",
    "outputId": "3fdd7692-b7e4-4686-fa83-359bb9e6cbd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True, show_dtype=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LLtMyp1ctYDU"
   },
   "outputs": [],
   "source": [
    "model.compile(loss =\"sparse_categorical_crossentropy\",\n",
    "            optimizer = keras.optimizers.SGD(learning_rate=0.03),\n",
    "              metrics= [\"accuracy\"]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sL8D8D5WurRh",
    "outputId": "b5ddf5ad-cd08-42f7-d249-e017c554ade5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-01 04:54:24.606544: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-01-01 04:54:24.613870: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2499995000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7992 - accuracy: 0.7293 - val_loss: 0.4647 - val_accuracy: 0.8356\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4384 - accuracy: 0.8444 - val_loss: 0.3829 - val_accuracy: 0.8656\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3894 - accuracy: 0.8606 - val_loss: 0.3779 - val_accuracy: 0.8650\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3496 - accuracy: 0.8755 - val_loss: 0.3888 - val_accuracy: 0.8562\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3391 - accuracy: 0.8769 - val_loss: 0.3565 - val_accuracy: 0.8732\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3187 - accuracy: 0.8828 - val_loss: 0.3263 - val_accuracy: 0.8846\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3039 - accuracy: 0.8883 - val_loss: 0.3424 - val_accuracy: 0.8772\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2926 - accuracy: 0.8920 - val_loss: 0.3165 - val_accuracy: 0.8874\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2795 - accuracy: 0.8977 - val_loss: 0.3111 - val_accuracy: 0.8892\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2681 - accuracy: 0.9006 - val_loss: 0.3240 - val_accuracy: 0.8824\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2617 - accuracy: 0.9019 - val_loss: 0.2988 - val_accuracy: 0.8888\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2500 - accuracy: 0.9080 - val_loss: 0.2916 - val_accuracy: 0.8942\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2505 - accuracy: 0.9076 - val_loss: 0.3027 - val_accuracy: 0.8922\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2454 - accuracy: 0.9103 - val_loss: 0.3002 - val_accuracy: 0.8932\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2345 - accuracy: 0.9130 - val_loss: 0.3043 - val_accuracy: 0.8888\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2227 - accuracy: 0.9176 - val_loss: 0.3095 - val_accuracy: 0.8912\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2159 - accuracy: 0.9196 - val_loss: 0.2885 - val_accuracy: 0.8966\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2136 - accuracy: 0.9216 - val_loss: 0.2869 - val_accuracy: 0.8984\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2066 - accuracy: 0.9232 - val_loss: 0.2836 - val_accuracy: 0.9006\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2020 - accuracy: 0.9257 - val_loss: 0.2910 - val_accuracy: 0.9002\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2012 - accuracy: 0.9281 - val_loss: 0.2825 - val_accuracy: 0.8990\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1914 - accuracy: 0.9289 - val_loss: 0.3041 - val_accuracy: 0.8900\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1901 - accuracy: 0.9299 - val_loss: 0.3024 - val_accuracy: 0.8946\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1823 - accuracy: 0.9314 - val_loss: 0.2912 - val_accuracy: 0.8950\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1813 - accuracy: 0.9334 - val_loss: 0.3003 - val_accuracy: 0.8948\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1750 - accuracy: 0.9350 - val_loss: 0.2935 - val_accuracy: 0.8980\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1683 - accuracy: 0.9377 - val_loss: 0.2843 - val_accuracy: 0.9000\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1634 - accuracy: 0.9398 - val_loss: 0.3073 - val_accuracy: 0.8966\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1591 - accuracy: 0.9429 - val_loss: 0.2972 - val_accuracy: 0.9016\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1568 - accuracy: 0.9418 - val_loss: 0.3043 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "7lG2R9LTvr0q",
    "outputId": "a4c922c8-ab3e-4f8d-8237-6941b0285da9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1ZCLZPvBt-T",
    "outputId": "1d7f9897-3168-4f39-db99-f89f9b7e0531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.8885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34407684206962585, 0.8884999752044678]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m6ISo51cKIXJ",
    "outputId": "00f06750-740f-4ae0-ce04-e135def4a819"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cWJUtZ3swTDD",
    "outputId": "c0d0472d-b5d9-40db-85d3-b41aadfceedd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_new), axis = 1)\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PP0Ww8v5xiJN",
    "outputId": "044c8a96-d11f-4e2d-ba42-3de0d26a161e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "TQwUXs8oyZqn"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZ0VKNIQzfli",
    "outputId": "82ae998b-2678-47d2-d017-8f062f97a202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.7690 - val_loss: 0.5411\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 853us/step - loss: 0.5448 - val_loss: 0.4809\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.4914 - val_loss: 0.4578\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.4705 - val_loss: 0.4561\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.4715 - val_loss: 0.4394\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 851us/step - loss: 0.4467 - val_loss: 0.4304\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 859us/step - loss: 0.4737 - val_loss: 0.4255\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 874us/step - loss: 0.4545 - val_loss: 0.4228\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.4292 - val_loss: 0.4184\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.4248 - val_loss: 0.4124\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.4318 - val_loss: 0.4074\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.4240 - val_loss: 0.4068\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 859us/step - loss: 0.4257 - val_loss: 0.4073\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.4140 - val_loss: 0.3975\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 857us/step - loss: 0.4155 - val_loss: 0.3893\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.3928 - val_loss: 0.3864\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3871 - val_loss: 0.3850\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.4042 - val_loss: 0.3856\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.3979 - val_loss: 0.3789\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.3857 - val_loss: 0.3760\n",
      "162/162 [==============================] - 0s 531us/step - loss: 0.3828\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "                                 keras.layers.Dense(30, activation=\"relu\", input_shape= X_train.shape[1:]),\n",
    "                                 keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss = \"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs = 20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "m-FPnkHY5MFq",
    "outputId": "9b9d3135-3312-49fa-ad1b-19cebde128af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "miyLXqwr1uen"
   },
   "source": [
    "from numpy.core.fromnumeric import shape\n",
    "input_ = keras.layers.Input(shape= X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "Concatenate = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(Concatenate)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "yBUvCthB26Ak"
   },
   "source": [
    "model = keras.Model(inputs = [input_], outputs = [output])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "1QVTKWx73PZz"
   },
   "source": [
    "model.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqDVwxqx4uKZ",
    "outputId": "6f729c29-a482-412f-c45c-9bbbda1bbec2"
   },
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "9GV81f0g5GUF"
   },
   "source": [
    "input_A = keras.layers.Input(shape=[5], name = \"wide input\")\n",
    "input_B = keras.layers.Input(shape=[6], name = \"deep input\")\n",
    "hidden1 = keras.layers.Dense(30, activation = \"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation = \"relu\")(hidden1)\n",
    "Concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(Concat)\n",
    "model = keras.Model(inputs = [input_A, input_B], outputs = [output])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "hKhZkoqa47Xf"
   },
   "source": [
    "model.compile(optimizer = keras.optimizers.SGD(learning_rate=1e-3), loss = \"mse\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "L-hm2Sok7d8f"
   },
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zNDGrlUv8IH5",
    "outputId": "5b2b719a-6a6a-43dc-e310-11fa3b12b449"
   },
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "1QS_c72j8rew",
    "outputId": "27230f0d-88ce-4979-ec44-e1b086c96d51"
   },
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "  def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "      super().__init__(**kwargs)\n",
    "      self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "      self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "      self.main_output = keras.layers.Dense(1)\n",
    "      self.aux_output = keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    input_A, input_B = inputs\n",
    "    hidden1 = self.hidden1(input_A)\n",
    "    hidden2 = self.hidden2(input_B)\n",
    "    concat = keras.layers.concatenate([input_A, input_B])\n",
    "    main_output = self.main_output(concat)\n",
    "    aux_output = self.aux_output(hidden2)\n",
    "    return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "wDGBS7nT3V3K"
   },
   "source": [
    "model.save(\"my_keras_model.h5\") #Save models. Only works with sequential & functional APIs but not subclass API\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") #Load model. Only works with sequential & functional APIs but not subclass API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\n",
    "Callbacks can be used as argument to fit() method to specify a list of objects that Keras will call at the start and end of training, at the start and end of each epoch, and even before and after processing a batch."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "history = model.fit(X_train_A , y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set save_best_only=True when creating ModelCheckpoint if using a validation set, so that it will save the model only when its performance on the validation set is the best so far. This way we don't need to worry about training for too long and overfitting the training set; simply restore the last model saved after training, and this will be the best model on the validation set.\n",
    "\n",
    "The following is a simple way to implement early stopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.3925 - val_loss: 0.3719\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 888us/step - loss: 0.3923 - val_loss: 0.3761\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 925us/step - loss: 0.3852 - val_loss: 0.3757\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.3956 - val_loss: 0.3830\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.3869 - val_loss: 0.3736\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.3813 - val_loss: 0.3687\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.3882 - val_loss: 0.3631\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.3782 - val_loss: 0.3696\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3788 - val_loss: 0.3629\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 876us/step - loss: 0.4794 - val_loss: 0.3671\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.3791 - val_loss: 0.3733\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3779 - val_loss: 0.3613\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3739 - val_loss: 0.3568\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.3715 - val_loss: 0.3615\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.3717 - val_loss: 0.3714\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.3708 - val_loss: 0.3718\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.3752 - val_loss: 0.3609\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3739 - val_loss: 0.3641\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3672 - val_loss: 0.3577\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.3658 - val_loss: 0.3552\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.3644 - val_loss: 0.3513\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3614 - val_loss: 0.3521\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 879us/step - loss: 0.3611 - val_loss: 0.3499\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.3592 - val_loss: 0.3505\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 857us/step - loss: 0.3587 - val_loss: 0.3527\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.3569 - val_loss: 0.3492\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3559 - val_loss: 0.3451\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 875us/step - loss: 0.3565 - val_loss: 0.3459\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3543 - val_loss: 0.3456\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.3555 - val_loss: 0.3453\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
    "                                               save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to implement early stopping is to use the EarlyStopping callback. It will interrupt training when it measures no progress on the validation set for a number of epochs (defined by *patience* argument), and it will optionally roll back to the best model.\n",
    "\n",
    "We can implement both callbacks to save checkpoints of the model and interrupt training early when there is no more progress (to avoid wasting time and resources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3555 - val_loss: 0.3568\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3672 - val_loss: 0.3697\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3529 - val_loss: 0.3490\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3532 - val_loss: 0.3512\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.3545 - val_loss: 0.3541\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.3545 - val_loss: 0.3468\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3500 - val_loss: 0.3431\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3624 - val_loss: 0.3449\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.3508 - val_loss: 0.3528\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3498 - val_loss: 0.3558\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 876us/step - loss: 0.3476 - val_loss: 0.3415\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 857us/step - loss: 0.3468 - val_loss: 0.3423\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.3512 - val_loss: 0.3441\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.3466 - val_loss: 0.3391\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3446 - val_loss: 0.3350\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.3457 - val_loss: 0.3373\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.3423 - val_loss: 0.3324\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.3411 - val_loss: 0.3313\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.3424 - val_loss: 0.3327\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.3399 - val_loss: 0.3366\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 859us/step - loss: 0.3430 - val_loss: 0.3357\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.3388 - val_loss: 0.3341\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3394 - val_loss: 0.3344\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 886us/step - loss: 0.3380 - val_loss: 0.3307\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 857us/step - loss: 0.3377 - val_loss: 0.3307\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.3373 - val_loss: 0.3321\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 859us/step - loss: 0.3364 - val_loss: 0.3356\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 859us/step - loss: 0.3365 - val_loss: 0.3359\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.3355 - val_loss: 0.3287\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.3373 - val_loss: 0.3436\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.3375 - val_loss: 0.3253\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.3351 - val_loss: 0.3283\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.3370 - val_loss: 0.3320\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.3359 - val_loss: 0.3261\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.3338 - val_loss: 0.3253\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.3342 - val_loss: 0.3310\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.3340 - val_loss: 0.3275\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.3537 - val_loss: 0.3289\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.3387 - val_loss: 0.3282\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.3358 - val_loss: 0.3302\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3333 - val_loss: 0.3402\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, \n",
    "                                                 restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write custom callbacks if we need more control.\n",
    "\n",
    "The following custom callback will display the ratio between validation loss and training loss during training, (e.g. to detect overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks can be used during evaluation and predictions for debugging.\n",
    "\n",
    "* For evaluation, we should implement on_test_begin(), on_test_end(), on_test_batch_begin(), on_test_batch_end() (called by evaluate()).\n",
    "* For prediction, we should implement on_predict_begin(), on_predict_end(), on_predict_batch_begin(), on_predict_batch_end() (called by predict())."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard can be used for visualization to view learning curves during training, view learning curves between multiple runs, visualize computational graphs, analyse training statistics, view images generated by the model, visualize complex multidimensional data projected down to 3D, etc.\n",
    "\n",
    "To use it, the program must be modified to output the data we want to visualize to binary log files called *event files*. Each binary record is called a *summary*.\n",
    "The Tensorboard server will monitor the log directory, and will automatically pick up changes and update the visualizations, which allows us to visualize live data.\n",
    "In general, you want to point the Tensorboard server to a root log directory and configure the program so that it writes to a different subdirectory every time it runs. This will help to compare multiple runs without mixing things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "197/363 [===============>..............] - ETA: 0s - loss: 0.3250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-01 04:56:28.061145: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2022-01-01 04:56:28.061175: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2022-01-01 04:56:28.061216: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2022-01-01 04:56:28.103498: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2022-01-01 04:56:28.103535: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2022-01-01 04:56:28.106011: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2022-01-01 04:56:28.111608: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2022-01-01 04:56:28.118243: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./my_logs/run_2022_01_01-04_56_28/train/plugins/profile/2022_01_01_04_56_28\n",
      "2022-01-01 04:56:28.118750: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./my_logs/run_2022_01_01-04_56_28/train/plugins/profile/2022_01_01_04_56_28/default.trace.json.gz\n",
      "2022-01-01 04:56:28.127677: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./my_logs/run_2022_01_01-04_56_28/train/plugins/profile/2022_01_01_04_56_28\n",
      "2022-01-01 04:56:28.127777: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./my_logs/run_2022_01_01-04_56_28/train/plugins/profile/2022_01_01_04_56_28/default.memory_profile.json.gz\n",
      "2022-01-01 04:56:28.127915: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./my_logs/run_2022_01_01-04_56_28/train/plugins/profile/2022_01_01_04_56_28Dumped tool data for xplane.pb to ./my_logs/run_2022_01_01-04_56_28/train/plugins/profile/2022_01_01_04_56_28/default.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./my_logs/run_2022_01_01-04_56_28/train/plugins/profile/2022_01_01_04_56_28/default.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./my_logs/run_2022_01_01-04_56_28/train/plugins/profile/2022_01_01_04_56_28/default.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./my_logs/run_2022_01_01-04_56_28/train/plugins/profile/2022_01_01_04_56_28/default.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./my_logs/run_2022_01_01-04_56_28/train/plugins/profile/2022_01_01_04_56_28/default.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 0.3310\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.3339 - val_loss: 0.3238\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.3335 - val_loss: 0.3412\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.3346 - val_loss: 0.3247\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.3351 - val_loss: 0.3469\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.3472 - val_loss: 0.3281\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.3328 - val_loss: 0.3233\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 874us/step - loss: 0.3319 - val_loss: 0.3351\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.3315 - val_loss: 0.3277\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.3310 - val_loss: 0.3265\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.3354 - val_loss: 0.3218\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.3323 - val_loss: 0.3224\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3316 - val_loss: 0.3209\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.3293 - val_loss: 0.3215\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 888us/step - loss: 0.3307 - val_loss: 0.3344\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.3311 - val_loss: 0.3246\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3281 - val_loss: 0.3224\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.3294 - val_loss: 0.3222\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.3275 - val_loss: 0.3224\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 877us/step - loss: 0.3268 - val_loss: 0.3214\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.3290 - val_loss: 0.3191\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.3337 - val_loss: 0.3404\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.3370 - val_loss: 0.3218\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.5436 - val_loss: 0.3301\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 874us/step - loss: 0.3361 - val_loss: 0.3227\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3312 - val_loss: 0.3235\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 877us/step - loss: 0.3282 - val_loss: 0.3230\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.3285 - val_loss: 0.3221\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.3270 - val_loss: 0.3192\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.3274 - val_loss: 0.3227\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30, \n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-501824846c5479ad\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-501824846c5479ad\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_logs --port=6006 --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning NN hyperparameters\n",
    "\n",
    "We can use GridSearchCV or RandomizedSearchCV to find the best possible combinations of hyperparameters.\n",
    "\n",
    "To do this, the first step is to create a function that will build and compile a keras model, given a set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.3716 - val_loss: 0.6760\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 879us/step - loss: 0.6969 - val_loss: 0.5837\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.5979 - val_loss: 0.5414\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.5364 - val_loss: 0.5116\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.5230 - val_loss: 0.4935\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 875us/step - loss: 0.5034 - val_loss: 0.4757\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 875us/step - loss: 0.4837 - val_loss: 0.4664\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.4732 - val_loss: 0.4606\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.4583 - val_loss: 0.4519\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.4851 - val_loss: 0.4476\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.4575 - val_loss: 0.4425\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.4626 - val_loss: 0.4377\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.4538 - val_loss: 0.4351\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.4376 - val_loss: 0.4312\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.4383 - val_loss: 0.4332\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.4525 - val_loss: 0.4262\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.4366 - val_loss: 0.4232\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 875us/step - loss: 0.4353 - val_loss: 0.4200\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 863us/step - loss: 0.4388 - val_loss: 0.4178\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.4489 - val_loss: 0.4163\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 875us/step - loss: 0.4185 - val_loss: 0.4131\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.4293 - val_loss: 0.4106\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.4199 - val_loss: 0.4100\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 863us/step - loss: 0.4391 - val_loss: 0.4075\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.4266 - val_loss: 0.4054\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.4197 - val_loss: 0.4041\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.4181 - val_loss: 0.4034\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.4142 - val_loss: 0.4006\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 875us/step - loss: 0.4053 - val_loss: 0.4014\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.3973 - val_loss: 0.3975\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.4077 - val_loss: 0.3968\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.4158 - val_loss: 0.3947\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.4169 - val_loss: 0.3936\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.4189 - val_loss: 0.3929\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.4033 - val_loss: 0.3937\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.3990 - val_loss: 0.3912\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.3964 - val_loss: 0.3892\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 863us/step - loss: 0.3983 - val_loss: 0.3890\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.4068 - val_loss: 0.3886\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3986 - val_loss: 0.3882\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.4143 - val_loss: 0.3852\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.3982 - val_loss: 0.3841\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 876us/step - loss: 0.3938 - val_loss: 0.3847\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.4057 - val_loss: 0.3859\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.3978 - val_loss: 0.3835\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.4021 - val_loss: 0.3817\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.3963 - val_loss: 0.3798\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.3955 - val_loss: 0.3787\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.3926 - val_loss: 0.3780\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.4106 - val_loss: 0.3770\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 863us/step - loss: 0.3948 - val_loss: 0.3759\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 859us/step - loss: 0.3857 - val_loss: 0.3759\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.4112 - val_loss: 0.3755\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.3916 - val_loss: 0.3744\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.3906 - val_loss: 0.3816\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.3931 - val_loss: 0.3760\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.3792 - val_loss: 0.3730\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.4098 - val_loss: 0.3741\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.3715 - val_loss: 0.3706\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.3790 - val_loss: 0.3729\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 874us/step - loss: 0.3686 - val_loss: 0.3708\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3846 - val_loss: 0.3692\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 880us/step - loss: 0.3810 - val_loss: 0.3951\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.4561 - val_loss: 0.3686\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.3817 - val_loss: 0.3691\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 885us/step - loss: 0.3759 - val_loss: 0.3678\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.3785 - val_loss: 0.3670\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.3707 - val_loss: 0.3680\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 874us/step - loss: 0.3882 - val_loss: 0.3677\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.3991 - val_loss: 0.3716\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.3828 - val_loss: 0.3644\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 896us/step - loss: 0.3762 - val_loss: 0.3626\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.3713 - val_loss: 0.3638\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 874us/step - loss: 0.3585 - val_loss: 0.3638\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.3873 - val_loss: 0.3626\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.3938 - val_loss: 0.3616\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.3773 - val_loss: 0.3614\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.3784 - val_loss: 0.3604\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 879us/step - loss: 0.3730 - val_loss: 0.3608\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.3749 - val_loss: 0.3600\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.3571 - val_loss: 0.3592\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 879us/step - loss: 0.3629 - val_loss: 0.3577\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.3498 - val_loss: 0.3594\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.3860 - val_loss: 0.3577\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.3661 - val_loss: 0.3567\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 883us/step - loss: 0.3584 - val_loss: 0.3593\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.3493 - val_loss: 0.3551\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.3718 - val_loss: 0.3558\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.3603 - val_loss: 0.3542\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.3727 - val_loss: 0.3555\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.3628 - val_loss: 0.3602\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 874us/step - loss: 0.3731 - val_loss: 0.3553\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3538 - val_loss: 0.3523\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 877us/step - loss: 0.3702 - val_loss: 0.3528\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.3541 - val_loss: 0.3519\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3545 - val_loss: 0.3533\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 874us/step - loss: 0.3599 - val_loss: 0.3597\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.3496 - val_loss: 0.3623\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.3613 - val_loss: 0.3525\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.3582 - val_loss: 0.3502\n",
      "162/162 [==============================] - 0s 543us/step - loss: 0.3513\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, validation_data = (X_valid, y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\" : [0, 1, 2, 3],\n",
    "    \"n_neurons\" : np.arange(1, 100),\n",
    "    \"learning_rate\" : reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                 validation_data = (X_valid, y_valid),\n",
    "                 callbacks = [keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, increasing the no. of layers instead of no. of neurons is more efficient.\n",
    "\n",
    "It's often simpler and more efficient to pick a model with more layers & neurons than required and use earlystopping and other regularization techniques to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate\n",
    "\n",
    "Learning rate is the most important hyperparameter.\n",
    "\n",
    "One way to find a good learning rate is to train the model for a few hundred iterations, starting with a very low rate (ex. 10^-5) and gradually increasing to a very large value (ex. 10). This is done by multiplying the learning rate by a constant factor at each iteration (ex. by exp(log(10^6)/500) to go from 10^-5 to 10 in 500 iterations).\n",
    "\n",
    "We can then reinitialize the model and train it normally using this good learning rate.\n",
    "\n",
    "The optimal learning rate depends on other hyperparameters such as batch size. So if we modify any hyperparameter, we have to ensure that we update learning rate as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO+eOuRD1yq09pABu5mgLX+",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Intro to ANN with Keras .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "d2l:Python",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
